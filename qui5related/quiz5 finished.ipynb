{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ada53e6-a464-43a9-b470-c7c4a8a95c8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.1 Finite Difference: Calculation R -> R\n",
    "#### 省evaluation: forward & backward\n",
    "#### best error bound: central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c11a4f97-13b0-478f-8a64-8bcf12e85064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for\n",
      "-1.4085438483348172\n",
      "back\n",
      "-1.4493768436626169\n",
      "central\n",
      "-1.428960345998717\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import sympy as sym\n",
    "import math\n",
    "from math import e\n",
    "\n",
    "#change \n",
    "def f(t):\n",
    "    return -np.log(t) #去掉c\n",
    "xhat = 0.7  # point where we want to find the approximation\n",
    "h = 0.02   # initial perturbation / step size\n",
    "#change end\n",
    "\n",
    "#!!!看清题目用什么method： 选好\n",
    "#forward\n",
    "fval = f(xhat)  # we only need to evaluate this once!\n",
    "# one function evaluation per each perturbation size\n",
    "dfapprox1 = ( f(xhat+h) - fval ) / h  \n",
    "print(\"for\")\n",
    "print(dfapprox1)\n",
    "\n",
    "#backward\n",
    "dfapprox2 = ( fval - f(xhat-h) ) / h \n",
    "print(\"back\")\n",
    "print(dfapprox2)\n",
    "\n",
    "#central\n",
    "dfapprox3 = ( f(xhat+h) - f(xhat-h) ) / (2*h)\n",
    "print(\"central\")\n",
    "print(dfapprox3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea28caa-3fb9-491e-b604-1d4e6d444f7f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.2 Finite Difference Gradient\n",
    "#### 注意for/back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85ca887-4aa2-464b-a77f-ebc59790d2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n",
      "[3.  0.  4.1]\n",
      "backward\n",
      "[3.  0.  3.9]\n",
      "central\n",
      "[3. 0. 4.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import sympy as sym\n",
    "import math\n",
    "from math import e\n",
    "#change\n",
    "def fn(xvec):\n",
    "    x = xvec[0]\n",
    "    y = xvec[1]\n",
    "    z = xvec[2]\n",
    "    return x*z**2 + 2*x*z\n",
    "i = 1 # E: 0; F: 1\n",
    "rxs = [1,1,1] #approximation at point rxs\n",
    "h = 0.1\n",
    "\n",
    "n = 3   #row_num in E / vector_size\n",
    "#change end\n",
    "\n",
    "\n",
    "##审题！！！:  using \"forward\" finite difference method\n",
    "#finite diff method to fin Jacobian\n",
    "def forward(rxs, h, fn):\n",
    "    Jac = np.zeros(n)\n",
    "    fvaln = fn(rxs)\n",
    "    for i in range(n):\n",
    "        xfd = rxs.copy()\n",
    "        xfd[i] += h\n",
    "        # column i\n",
    "        Jac[i] = (fn(xfd) - fvaln)/h\n",
    "    E = -Jac\n",
    "    return E\n",
    "\n",
    "def backward(rxs, h, fn):\n",
    "    Jac = np.zeros(n)\n",
    "    fvaln = fn(rxs)\n",
    "    for i in range(n):\n",
    "        xfd = rxs.copy()\n",
    "        xfd[i] -= h\n",
    "        # column i\n",
    "        Jac[i] = (fvaln -fn(xfd))/h\n",
    "    E = -Jac #要求为负！！！！！！！！！！\n",
    "    return E\n",
    "def central(rxs, h, fn):\n",
    "    Jac = np.zeros(n)\n",
    "    fvaln = fn(rxs)\n",
    "    for i in range(n):\n",
    "        xfd1 = rxs.copy()\n",
    "        xfd2 = rxs.copy()\n",
    "        xfd1[i] -= h\n",
    "        xfd2[i] += h\n",
    "        # column i\n",
    "        Jac[i] = (fn(xfd2) -fn(xfd1))/(2*h)\n",
    "    E = -Jac #要求为负！！！！！！！！！！\n",
    "    return E\n",
    "\n",
    "print(\"forward\")\n",
    "print(forward(rxs, h, fn)*(-1)**i)\n",
    "print(\"backward\")\n",
    "print(backward(rxs, h, fn)*(-1)**i)\n",
    "print(\"central\")\n",
    "print(central(rxs, h, fn)*(-1)**i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff6a66d-9123-4bb6-81c1-80fc97212f0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1.1  One Step of Solving 1D Equations\n",
    "## Perform one step of Secant method\n",
    "## Perform Two Steps of Bisection\n",
    "Newton, secant, bisection  \n",
    "#### (df) root, 1d(1 equation), 1 variable, 1 or n steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de99b83-7b50-4c07-9043-1670e193be54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-sin(x)\n",
      "4.1663173646459395\n",
      "----Secant----\n",
      "dfap: -1 + cos(1)\n",
      "x2 : 2.1753426496700214\n",
      "----biscant----\n",
      "step1\n",
      "(2.5, 8)\n",
      "step2\n",
      "(2.5, 5.25)\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "def Newton_1D_step(x_prev, f_str, var_str):\n",
    "    '''\n",
    "    Given x_k, string representation of function, and string representation of variable\n",
    "    Return the numerical value of x_{k+1}\n",
    "    '''\n",
    "    f = sp.sympify(f_str)\n",
    "    var = sp.symbols(var_str)\n",
    "    df = sp.diff(f, var)\n",
    "    print(df)\n",
    "    x_next = x_prev - f.subs(var, x_prev) / df.subs(var, x_prev)\n",
    "    return float(x_next)\n",
    "\n",
    "def Newton_1D_step_aux(x_prev, f, df, var):\n",
    "    '''\n",
    "    Given x_k, function, differentiation of the function, and the variable\n",
    "    Return the numerical value of x_{k+1}\n",
    "    Operate as a lighter weighted version of Newton_1D_step\n",
    "    '''\n",
    "    return float(x_prev - f.subs(var, x_prev) / df.subs(var, x_prev))\n",
    "\n",
    "def Newton_1D(x_0, f_str, var_str, err_bound):\n",
    "    '''\n",
    "    Given initial value x_0, string representation of function, string representation of variable\n",
    "    as well as the error bound\n",
    "    Return the number of iterations it takes to get to the error bound\n",
    "    And the final value\n",
    "    '''\n",
    "    f = sp.sympify(f_str)\n",
    "    var = sp.symbols(var_str)\n",
    "    df = sp.diff(f, var)\n",
    "    x_curr = x_0\n",
    "    iterations = 0\n",
    "    while abs(float(f.subs(var, x_curr))) > err_bound:\n",
    "        x_curr = Newton_1D_step_aux(x_curr, f, df, var)\n",
    "        iterations += 1\n",
    "    return iterations, x_curr\n",
    "\n",
    "def secant_1D_step(x_prev0, x_prev1, f_str, var_str):\n",
    "    '''\n",
    "    Given x_{k-1}, x_{k}, string representation of function, and string representation of variable\n",
    "    Return the numerical value of x_{k+1}\n",
    "    '''\n",
    "    f = sp.sympify(f_str)\n",
    "    var = sp.symbols(var_str)\n",
    "    x_next = x_prev1 - f.subs(var, x_prev1) / ((f.subs(var, x_prev0) - f.subs(var, x_prev1)) / (x_prev0 - x_prev1))\n",
    "    return float(x_next), (f.subs(var, x_prev0) - f.subs(var, x_prev1)) / (x_prev0 - x_prev1)\n",
    "def bisection_1D_step(left, right, f_str, var_str):\n",
    "    f = sp.sympify(f_str)\n",
    "    var = sp.symbols(var_str)\n",
    "    mid = (left + right) / 2\n",
    "    if float(f.subs(var, left) * f.subs(var, mid)) < 0:\n",
    "        right = mid\n",
    "    else:\n",
    "        left = mid\n",
    "    return left, right\n",
    "'''\n",
    "sin(x/6)\n",
    "'''\n",
    "f_str = 'cos(x)'\n",
    "var_str = 'x'\n",
    "\n",
    "#Newton\n",
    "nx1 = 0.25 \n",
    "\n",
    "#Secant\n",
    "sx0 = 1\n",
    "sx1 = 0\n",
    "\n",
    "#biscant\n",
    "a = -3\n",
    "b = 8\n",
    "j = 2 # bisc iteration\n",
    "\n",
    "newton_res = Newton_1D_step(nx1, f_str, var_str)\n",
    "\n",
    "secant_res = secant_1D_step(sx0, sx1, f_str, var_str)\n",
    "\n",
    "bi = []\n",
    "temp = bisection_1D_step(a, b, f_str, var_str)\n",
    "bi.append(temp)\n",
    "for i in range(j - 1):\n",
    "    temp = bisection_1D_step(temp[0], temp[1], f_str, var_str)\n",
    "    bi.append(temp)\n",
    "\n",
    "print(newton_res)\n",
    "print(\"----Secant----\")\n",
    "print(\"dfap:\", secant_res[1])\n",
    "print(\"x2 :\", secant_res[0])\n",
    "print(\"----biscant----\")\n",
    "print(\"step1\")\n",
    "print(bi[0])\n",
    "print(\"step2\")\n",
    "print(bi[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dfc534-c538-4ad9-a015-0c6953c7a674",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.1.2 Perform Two Steps of Newton's Method\n",
    "#### root(df); 1d; 1 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b6d2807-f47b-42d8-9941-043b16cd5894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0\n",
      "1   0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 0.2462686567164179)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "def Newton_1D_step(x_prev, f_str, var_str):\n",
    "    '''\n",
    "    Given x_k, string representation of function, and string representation of variable\n",
    "    Return the numerical value of x_{k+1}\n",
    "    '''\n",
    "    f = sp.sympify(f_str)\n",
    "    var = sp.symbols(var_str)\n",
    "    df = sp.diff(f, var)\n",
    "    x_next = x_prev - f.subs(var, x_prev) / df.subs(var, x_prev)\n",
    "    return float(x_next)\n",
    "\n",
    "def Newton_1D_step_aux(x_prev, f, df, var):\n",
    "    '''\n",
    "    Given x_k, function, differentiation of the function, and the variable\n",
    "    Return the numerical value of x_{k+1}\n",
    "    Operate as a lighter weighted version of Newton_1D_step\n",
    "    '''\n",
    "    return float(x_prev - f.subs(var, x_prev) / df.subs(var, x_prev))\n",
    "\n",
    "def Newton_1D(x_0, f_str, var_str, err_bound):\n",
    "    '''\n",
    "    Given initial value x_0, string representation of function, string representation of variable\n",
    "    as well as the error bound\n",
    "    Return the number of iterations it takes to get to the error bound\n",
    "    And the final value\n",
    "    '''\n",
    "    f = sp.sympify(f_str)\n",
    "    var = sp.symbols(var_str)\n",
    "    df = sp.diff(f, var)\n",
    "    x_curr = x_0\n",
    "    iterations = 0\n",
    "    while abs(float(f.subs(var, x_curr))) > err_bound:\n",
    "        print(iterations, \" \", x_curr)\n",
    "        x_curr = Newton_1D_step_aux(x_curr, f, df, var)\n",
    "        iterations += 1\n",
    "    return iterations, x_curr\n",
    "x0 = 0\n",
    "fx = 'x**3 + 4*x - 1'\n",
    "p = -3\n",
    "Newton_1D(x0, fx, 'x', 10**p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74651158-4d53-4c94-b5c8-34777c663e1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.1.3 Determine the length of the interval\n",
    "#### bisection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1550ed3e-c18d-4d0b-8329-9564f66f0e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bisection Method\n",
    "# Q: the length of the interval after ? iterations of bisection\n",
    "import numpy as np\n",
    "\n",
    "#change\n",
    "L = -7\n",
    "R = 12\n",
    "iteration_num = 4 #  after ? iterations of bisection\n",
    "\n",
    "def function(x):\n",
    "    return (x-4)**3\n",
    "#change end\n",
    "\n",
    "def bisetic(inter, iteration_num):\n",
    "    a = inter[0]\n",
    "    b = inter[1]\n",
    "    interval_length = 0\n",
    "    if (a >= b or np.sign(function(a)) == np.sign(function(b))):\n",
    "        return None\n",
    "    fa = function(a)\n",
    "    for i in range(iteration_num):\n",
    "        m = (a+b)/2\n",
    "        fm = function(m)  \n",
    "        if  np.sign(fa) == np.sign(fm):\n",
    "            a = m \n",
    "            fa = fm \n",
    "        else:\n",
    "            b = m\n",
    "        interval_length = np.abs(a-b)\n",
    "    return interval_length\n",
    "\n",
    "interval = [L, R]\n",
    "bisetic(interval, iteration_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5963057-c274-41b7-a340-db93ad71870c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2(a) Newton Solve\n",
    "#### root(df), nd(2 equations), 2 variables, 1 step\n",
    "NewtonND-triangular  \n",
    "Jocobian & x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b22f8585-2356-49ef-bf77-d7a08f17bedb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  6.,   3.],\n",
       "        [-10.,   4.]]),\n",
       " array([-0.96296296, -0.40740741]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import sympy as sp\n",
    "#s1 build f\n",
    "def subs_all(formula, variables, values):\n",
    "    '''\n",
    "    helper function for Jocabian\n",
    "    You know what, it's getting to the point where this function\n",
    "    is necessary\n",
    "    '''\n",
    "    result = formula\n",
    "    for i in range(len(values)):\n",
    "        result = result.subs(variables[i], values[i])\n",
    "    return float(result.evalf())\n",
    "\n",
    "def calculated_jacobian(fs, variables, x_k):\n",
    "    '''\n",
    "    fs need to EQUAL TO ZERO!\n",
    "    '''\n",
    "    size = len(fs)\n",
    "    result = np.zeros((size, size))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            result[i][j] = subs_all(sp.diff(fs[i], variables[j]), variables, x_k)\n",
    "    return result\n",
    "\n",
    "def newton_nd_step(x_prev, f_strs, var_str):\n",
    "    '''\n",
    "    Given x_k, string of functions equal to 0, and string for variables: \n",
    "    calculate the parameter for the next iteration of Newton's method \n",
    "    for solving ND non-linear system of equations\n",
    "    '''\n",
    "    fs = [sp.sympify(f_str) for f_str in f_strs]\n",
    "    variables = sp.symbols(var_str)\n",
    "    jac = calculated_jacobian(fs, variables, x_prev)\n",
    "    f_vals = np.array([subs_all(f, variables, x_prev) for f in fs])\n",
    "    s = la.solve(jac, -1*f_vals)\n",
    "    return jac, x_prev+s\n",
    "\n",
    "# Workspace\n",
    "'''\n",
    "x0\n",
    "fv: f vector\n",
    "variable\n",
    "'''\n",
    "\n",
    "f1 = '-3*x**2 + -3*x + 3 + 2*y**2 + 2*y + 3*x*y'\n",
    "f2 = '3*x**2 - 2*x - 1 + 2*y**2 - 2*y - 2*x*y'\n",
    "\n",
    "\n",
    "f3 = '4*x**3 + 2*y**4 - 6'\n",
    "f4 = '6*x**2 + 3*y -5'\n",
    "\n",
    "x0 = [-1, 1]\n",
    "fv = [f1, f2]\n",
    "var = 'x y'\n",
    "newton_nd_step(x0, fv, var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d647b-e696-45fa-9bea-a3924e419132",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.2(b) Newton Solve 2 \n",
    "#### root(df), nd(2 equations), 2 variable, 1 step, get x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "247225e7-17a2-4f16-a0c3-3cf9ddb0dad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66666667, -0.25      ])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import sympy as sym\n",
    "x1, x2 = sym.symbols('x1 x2')\n",
    "# x, y, z = sym.symbols('x y z')\n",
    "\n",
    "#change\n",
    "#the function should be as the form: .... = 0\n",
    "fnt = np.array([3*x1*x2-4, x1**3+(x2**2)+5])\n",
    "rxs = [0, 2]  #initial guess x0\n",
    "#change end\n",
    "\n",
    "\n",
    "#find J\n",
    "n = fnt.shape[0]\n",
    "J = np.zeros((n,n))\n",
    "xs = [x1, x2]\n",
    "# xs = [x, y, z]\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        diff = sym.diff(fnt[i], xs[j])\n",
    "        J[i,j] = diff.evalf(subs={xs[0]:rxs[0], xs[1]:rxs[1]})\n",
    "\n",
    "# Newton's method: the resulting approximate solution after 1 iteration \n",
    "f = np.zeros_like(fnt)\n",
    "for i in range(len(fnt)):\n",
    "    f[i] = (fnt[i].evalf(subs={xs[0]:rxs[0], xs[1]:rxs[1]}))\n",
    "    \n",
    "f = f.astype(np.float64)\n",
    "rxs + la.solve(J, -f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260571f-821d-4806-8494-3baf21ea2c46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.1.1(a) Perform One Step of Golden Section Search\n",
    "#### op 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60225def-70cb-48ad-8520-fb063a5ed1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7294901687515765 12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# change\n",
    "def f(x):\n",
    "    return (x-6.2)**4\n",
    "a = -3 #LB of the starting interval\n",
    "b = 12  #UB of the starting interval\n",
    "iteration_num = 1 # next iteration\n",
    "# change end\n",
    "\n",
    "\n",
    "brackets = []\n",
    "tau = (np.sqrt(5)-1)/2\n",
    "m1 = a + (1 - tau) * (b - a)\n",
    "m2 = a + tau * (b - a)\n",
    "\n",
    "f1 = f(m1)\n",
    "f2 = f(m2)\n",
    "interval = np.abs(m1-m2)  \n",
    "x1 = m1\n",
    "x2 = m2\n",
    "a0 = a\n",
    "b0 = b\n",
    "\n",
    "for i in range(iteration_num):\n",
    "    if  f1>f2:\n",
    "        a0 = x1\n",
    "        x1 = x2\n",
    "        f1 = f2\n",
    "        h_k = b0-a0\n",
    "        x2 = a0 + tau * h_k\n",
    "        f2 = f(x2)\n",
    "    else:\n",
    "        b0 = x2\n",
    "        x2 = x1\n",
    "        f2 = f1\n",
    "        h_k = b0-a0\n",
    "        x1 = a0 + (1-tau) * h_k\n",
    "        f1 = f(x1)\n",
    "    brackets.append([a,a0,b0,b])\n",
    "    interval = np.abs(a0-b0) #所求\n",
    "    \n",
    "print(brackets[0][1], brackets[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30501473-3808-480e-924d-f9ccf000c525",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.1.1(b) Determine the length of the interval after one iteration\n",
    "## Perform One Step of Golden Section Search\n",
    "#### op 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aad1df9-9737-4987-8665-a1d2cf05396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6737620787507357\n",
      "5\n",
      "4.326237921249264\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def f(x):\n",
    "    return (x - 3.7)**2\n",
    "a = -2\n",
    "b = 5\n",
    "\n",
    "brackets = []\n",
    "gs = (np.sqrt(5) - 1) / 2\n",
    "m1 = a + (1 - gs) * (b - a)\n",
    "m2 = a + gs * (b - a)\n",
    "epsilon = 1e-5\n",
    "\n",
    "# Begin your modifications below here\n",
    "f1 = f(m1)\n",
    "f2 = f(m2)\n",
    "h = b-a\n",
    "if f1 > f2:\n",
    "    a = m1\n",
    "    m1 = m2\n",
    "    f1 = f2\n",
    "    h *= gs\n",
    "    m2 = a + gs * h\n",
    "    f2 = f(m2)\n",
    "    brackets.append([a, m1, m2, b])\n",
    "else:\n",
    "    b = m2\n",
    "    m2 = m1\n",
    "    f2 = f1\n",
    "    h *= gs\n",
    "    m1 = a + (1 - gs) * h\n",
    "    f1 = f(m1)\n",
    "    brackets.append([a, m1, m2, b])\n",
    "print(a)\n",
    "print(b)\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd4cbb-ab89-4676-be4b-375020e28a31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.1.2 Carrying out Newton steps\n",
    "#### optimization(ddf)/minimum; 1d; 1 variable; 1 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4708b917-24c7-4136-91fa-c3d7c9156cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18823529411764717\n"
     ]
    }
   ],
   "source": [
    "#-e^(-x^2)\n",
    "import numpy as np\n",
    "def df(x):\n",
    "    return 2*x*np.exp(-x**2)\n",
    "def d2f(x):\n",
    "    return 2*np.exp(-x**2)*(1-2*x**2)\n",
    "x = 0.4 \n",
    "for i in range(1):\n",
    "    dfx = df(x)\n",
    "    d2fx = d2f(x)\n",
    "    xnew = x - dfx / d2fx\n",
    "    if np.abs(xnew-x) < 1e-8:\n",
    "        break\n",
    "    x = xnew \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1707c9cf-a5e5-47c8-8900-42526f6c8702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.033055065616578394\n"
     ]
    }
   ],
   "source": [
    "#cosx \n",
    "import numpy as np\n",
    "def df(x):\n",
    "    return -1*np.sin(x)\n",
    "def d2f(x):\n",
    "    return -1*np.cos(x)\n",
    "\n",
    "x = 0.45\n",
    "for i in range(1):\n",
    "    dfx = df(x)\n",
    "    d2fx = d2f(x)\n",
    "    xnew = x - dfx / d2fx\n",
    "    if np.abs(xnew-x) < 1e-8:\n",
    "        break\n",
    "    x = xnew \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05dcc089-b0d6-45dc-a84a-aaec5649299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.09542914752227516\n"
     ]
    }
   ],
   "source": [
    "#5*cosx**5 \n",
    "import numpy as np\n",
    "def df(x):\n",
    "    return -25*np.cos(x)**4*np.sin(x) \n",
    "def d2f(x):\n",
    "    return -25*(np.cos(x)**5 - 4*np.sin(x)**2*np.cos(x)**3)\n",
    "\n",
    "x = 0.25\n",
    "for i in range(1):\n",
    "    dfx = df(x)\n",
    "    d2fx = d2f(x)\n",
    "    xnew = x - dfx / d2fx\n",
    "    if np.abs(xnew-x) < 1e-8:\n",
    "        break\n",
    "    x = xnew \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e183e27b-142f-46b1-b04a-5b0dd9050685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8347826086956521\n"
     ]
    }
   ],
   "source": [
    "#-2e^(-6x^2)\n",
    "import numpy as np\n",
    "def df(x):\n",
    "    return 24*x*np.exp(-6*x**2)\n",
    "def d2f(x):\n",
    "    return 24*np.exp(-6*x**2)*(1-12*x**2)\n",
    "x = 0.4 \n",
    "\n",
    "for i in range(1):\n",
    "    dfx = df(x)\n",
    "    d2fx = d2f(x)\n",
    "    xnew = x - dfx / d2fx\n",
    "    if np.abs(xnew-x) < 1e-8:\n",
    "        break\n",
    "    x = xnew \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e838ca5-745a-498a-bab7-786fdfaec352",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2.1 N-Dimension Optimization using Steepest Descent\n",
    "#### op nd\n",
    "s0 = -df(x)  \n",
    "x1 = x0 + alpha* s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b85fcce-8ce5-42cd-b2bf-26d886976c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0 is  [ 19.40008999 -16.04710401]\n",
      "x1 is  [-2.6119982   2.67905792]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import sympy as sp\n",
    "import scipy.optimize as sopt\n",
    "def f(x):\n",
    "    a = x[0]\n",
    "    b = x[1]\n",
    "    return 11*a**2 + 11*a*b +11*b**2 + 12*np.sin(b)**2 + 11*np.cos(a*b)\n",
    "\n",
    "def df(x):\n",
    "    y = x[1]\n",
    "    x = x[0]\n",
    "    \n",
    "    return np.array([22*x + 11*y - 11*np.sin(x*y)*y,\n",
    "                     11*x + 22*y + 12*2*np.sin(y)*np.cos(y)-11*np.sin(x*y)*x ])\n",
    "\n",
    "\n",
    "      \n",
    "x = np.array([-3, 3])\n",
    "alpha = 0.02\n",
    "\n",
    "s = -df(x)\n",
    "xnew = x + alpha * s\n",
    "print(\"s0 is \", s)\n",
    "print(\"x1 is \", xnew)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b6677f-250b-437f-ab6d-08a1789bd275",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2.2 Optimization ND NewtonMethod one step\n",
    "## Carrying out Newton steps (n-dimensional)\n",
    "##  Optimization ND NewtonMethod get step: H, s0\n",
    "#### grad, hessian, x1, s0\n",
    "#### op ddf, 1d(1 equation), 2 variables, 1 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9fc02e-491e-478f-b1aa-702070143e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad is  [24.0, 18.0]\n",
      "hes is  [[72.0, 0.0], [0.0, 6.0]]\n",
      "x1 is [0.66666667 0.        ]\n",
      "s0 is [-0.33333333 -3.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import sympy as sp\n",
    "def gradient(formula, symbols, values=None):\n",
    "    '''\n",
    "    Given a SymPy formula and variables\n",
    "    Find its analytic gradient without substituion\n",
    "    as a list of SymPy formulae or numerical gradient\n",
    "    if values specified\n",
    "    '''\n",
    "    size = len(symbols)\n",
    "    gradient = []\n",
    "    for i in range(size):\n",
    "        gradient.append(formula.diff(symbols[i]))\n",
    "        \n",
    "    if values == None:\n",
    "        return gradient\n",
    "\n",
    "    # Make sure you don't mess up the analytical gradient\n",
    "    g_copy = gradient.copy()\n",
    "    gradient_at = []\n",
    "    for i in range(len(g_copy)):\n",
    "        for j in range(len(symbols)):\n",
    "            g_copy[i] = g_copy[i].subs(symbols[j], values[j])\n",
    "        gradient_at.append(float(g_copy[i].evalf()))\n",
    "    return gradient_at\n",
    "def subs_all(formula, variables, values):\n",
    "    '''\n",
    "    You know what, it's getting to the point where this function\n",
    "    is necessary\n",
    "    '''\n",
    "    result = formula\n",
    "    for i in range(len(values)):\n",
    "        result = result.subs(variables[i], values[i])\n",
    "    return float(result.evalf())\n",
    "def hessian(gradient, symbols, values=None):\n",
    "    '''\n",
    "    Given an analytic gradient and variables\n",
    "    Calculate its analytic Hessian\n",
    "    or numerical Hessian if values are specified\n",
    "    '''\n",
    "    size = len(symbols)\n",
    "    hessian = []\n",
    "    for i in range(size):\n",
    "        hessian.append([0]*size)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            hessian[i][j] = gradient[i].diff(symbols[j])\n",
    "            \n",
    "    if values == None:\n",
    "        return hessian\n",
    "    \n",
    "    hessian_at = hessian.copy()\n",
    "    size = len(hessian)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            hessian_at[i][j] = subs_all(hessian_at[i][j], symbols, [float(v) for v in values])\n",
    "#             for k in range(len(symbols)):\n",
    "#                 hessian_at[i][j] = hessian_at[i][j].subs(symbols[k], values[k])\n",
    "#             hessian_at[i][j] = float(hessian_at[i][j].evalf())\n",
    "    return hessian_at\n",
    "def newton_nd_optimization_crude_step(formula, symbols, x_prev):\n",
    "    x_prev = list(x_prev)\n",
    "    grad = gradient(formula, symbols)\n",
    "    neg_gradient_at = -1 * np.array(gradient(formula, symbols, values=x_prev))\n",
    "    hes_at = np.array(hessian(grad, symbols, values=x_prev))\n",
    "    return np.array(x_prev) + la.solve(hes_at, neg_gradient_at)\n",
    "\n",
    "form = sp.sympify('8*x**2 + 3*x*y + 8*y**2 + 10*E**(7*x*y) + 7*(sin(y)**2) + 14*cos(x*y)')\n",
    "form = sp.sympify(\"6*x**4 + 3*y**2\")\n",
    "#form = sp.sympify('E**(9*x) + 8*cos(y)')\n",
    "symbols = sp.symbols('x y')\n",
    "values = [1, 3]\n",
    "\n",
    "grad = gradient(form, symbols, values)\n",
    "hes = hessian(gradient(form, symbols), symbols, values)\n",
    "x_1 = newton_nd_optimization_crude_step(form, symbols, values)\n",
    "step = np.array(x_1) - np.array(values)\n",
    "print(\"grad is \", grad)\n",
    "print(\"hes is \", hes)\n",
    "print(\"x1 is\", x_1)\n",
    "print(\"s0 is\", step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9504ade3-e86d-42ba-9d6a-151c5f0dd967",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c831b06-be95-4ac8-bd6e-12c4c9ffc43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011852d-0612-471b-9f36-d79ac53e925a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898860d-4d4a-4b02-89e4-8a489f661a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d808135-e582-4b4b-9d4d-949d3a86a676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a738dd4-113c-4e7b-abf7-220246c309c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc27c426-ee7f-4395-8d23-d49680f3eb7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## C1 Finite Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a621cf43-f73e-4de0-89a7-61cad19a2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "'''\n",
    "S0: 方程\n",
    "S1：choice method\n",
    "'''\n",
    "def f(x):\n",
    "    return x[0]**2 + x[1]**5 + x[2]*x[5] + x[3]*x[5] +x[4]*x[5] + x[5]**4 + x[6]**4\n",
    "\n",
    "n = 7   \n",
    "def forward(rxs, h, f):\n",
    "    Jac = np.zeros(n)\n",
    "    fvaln = f(rxs)\n",
    "    for i in range(n):\n",
    "        xfd = rxs.copy()\n",
    "        xfd[i] += h\n",
    "        # column i\n",
    "        Jac[i] = (f(xfd) - fvaln)/h\n",
    "    return Jac\n",
    "approx_gradient = forward(xvec, 0.5, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d3f5d-c86d-4af6-9926-40b026276754",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## C2 Find the time to meet using Newton's method\n",
    "### When will they meet?\n",
    "root; 1d; find all xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c80b76-5835-4165-81cc-f16c3a2c2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "'''\n",
    "dis = 170\n",
    "xt + xj = 170\n",
    "'''\n",
    "def Newton_1D_step_aux(x_prev, f, df, var):\n",
    "    '''\n",
    "    Given x_k, function, differentiation of the function, and the variable\n",
    "    Return the numerical value of x_{k+1}\n",
    "    Operate as a lighter weighted version of Newton_1D_step\n",
    "    '''\n",
    "    return float(x_prev - f.subs(var, x_prev) / df.subs(var, x_prev))\n",
    "\n",
    "def Newton_1D(x_0, f_str, var_str, err_bound):\n",
    "    '''\n",
    "    Given initial value x_0, string representation of function, string representation of variable\n",
    "    as well as the error bound\n",
    "    Return the number of iterations it takes to get to the error bound\n",
    "    And the final value\n",
    "    '''\n",
    "    f = sp.sympify(f_str)\n",
    "    var = sp.symbols(var_str)\n",
    "    df = sp.diff(f, var)\n",
    "    x_curr = x_0\n",
    "    iterations = 0\n",
    "    all_guess = []\n",
    "    while abs(float(f.subs(var, x_curr))) > err_bound:\n",
    "        x_curr = Newton_1D_step_aux(x_curr, f, df, var)\n",
    "        all_guess.append(x_curr)\n",
    "        iterations += 1\n",
    "    return iterations, x_curr, all_guess\n",
    "\n",
    "f_str = '(x**3)/60 + x**2 + 30*cos(x) + 20*x - 170'\n",
    "var_str = 'x'\n",
    "t = Newton_1D(t_initial, f_str, var_str, epsilon)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2973b41e-bdc3-41e9-9a2f-5f46bc911ed7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## C3 Control the Temperature\n",
    "### How much wood is needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ee81a-2895-4389-9f9d-8fcccdc6ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "'''\n",
    "bisection method: shift 375 \n",
    "reach 375 degree\n",
    "w -> degreee\n",
    "'''\n",
    "def bisetic(left, right, function):\n",
    "    a = left\n",
    "    b = right\n",
    "    List = [(a,b)]\n",
    "    fa = function(a)\n",
    "    \n",
    "    while True:\n",
    "        m = (a+b)/2\n",
    "        fm = function(m)\n",
    "        \n",
    "        if (np.abs(fm - 375) < epsilon):\n",
    "             return m, List\n",
    "        if  np.sign(fa - 375) == np.sign(fm - 375):\n",
    "            a = m \n",
    "            fa = fm \n",
    "            List.append((a,b))\n",
    "        else:\n",
    "            b = m\n",
    "            List.append((a,b))\n",
    "    return None\n",
    "weight, intervals = bisetic(0, max_wood, get_temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908f7c2-96c7-4be6-93f0-c61274ee672d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## C4 Newton's Method\n",
    "root; nd  \n",
    "collect all xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17435aa-9d6c-4126-998a-0ca54d25d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "def f(w):\n",
    "    x, y, z = w\n",
    "    return np.array([\n",
    "        16*x**4 + 16*y**4 + z**4 - 16,\n",
    "        x**2    + y**2    + z**2 - 3,\n",
    "        x**3    - y])\n",
    "def df(w):\n",
    "    x, y, z = w\n",
    "    return np.array([\n",
    "        [64*x**3, 64*y**3, 4*z**3],\n",
    "        [2*x    , 2*y    ,2*z],\n",
    "        [3*x**2, - 1, 0]])\n",
    "\n",
    "\n",
    "guesses = np.zeros((5,3))\n",
    "\n",
    "# Initial guess, don't save this in output\n",
    "w = np.array([1.,1.,1.])\n",
    "for i in range(5):\n",
    "    s = -la.solve(df(w), f(w))\n",
    "    w = w + s\n",
    "    guesses[i] = w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd60a3e-a4d5-4945-b7a1-78ebd457daf5",
   "metadata": {},
   "source": [
    "## C5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03508d-9063-4c6e-9bbf-4878d5236ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb94c8cd-4424-4eac-9c81-f58c957133f4",
   "metadata": {},
   "source": [
    "## C6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95a931-58e9-425a-937c-82212712581d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
